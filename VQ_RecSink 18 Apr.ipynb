{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmukande-debug/VQ-Rec/blob/master/VQ_RecSink%2018%20Apr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO2PW4l9DB8X",
        "outputId": "cbfedd05-f019-4336-fa6f-c27c0b2d73d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VQ-Rec'...\n",
            "remote: Enumerating objects: 558, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 558 (delta 57), reused 15 (delta 5), pack-reused 451\u001b[K\n",
            "Receiving objects: 100% (558/558), 102.94 MiB | 16.74 MiB/s, done.\n",
            "Resolving deltas: 100% (232/232), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tmukande-debug/VQ-Rec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax4ULK2mk_2u",
        "outputId": "87f29c20-31ca-42dd-f722-11da40cd3178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-gpu==1.7.2\n",
            "  Downloading faiss_gpu-1.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-gpu==1.7.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMiK0AFUF6Qm"
      },
      "outputs": [],
      "source": [
        "!pip install recbole==1.0.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#! pip install x-transformers"
      ],
      "metadata": {
        "id": "Ek7-DP3HbkTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzX2bZJdrAJi"
      },
      "outputs": [],
      "source": [
        "! pip install sinkhorn_transformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113"
      ],
      "metadata": {
        "id": "xVGj2Kvautzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzDVDYdFHd-u",
        "outputId": "fdc27950-c813-4854-e948-b54b76bd5b0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VQ-Rec\n"
          ]
        }
      ],
      "source": [
        "%cd VQ-Rec/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1faR_WsnLgSo",
        "outputId": "eb07ed90-f9b9-4486-c620-20a852d5f9cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-18 20:16:27.749636: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-18 20:16:28.953848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Namespace(m='VQRec', d='Scientific', p='pretrained/VQRec-FHCKM-300.pth', f='')\n",
            "['props/VQRec.yaml', 'props/finetune.yaml']\n",
            "command line args [-d Scientific -p pretrained/VQRec-FHCKM-300.pth] will not be used in RecBole\n",
            "18 Apr 20:16    INFO  \n",
            "\u001b[1;35mGeneral Hyper Parameters:\n",
            "\u001b[0m\u001b[1;36mgpu_id\u001b[0m =\u001b[1;33m 0\u001b[0m\n",
            "\u001b[1;36muse_gpu\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36mseed\u001b[0m =\u001b[1;33m 2020\u001b[0m\n",
            "\u001b[1;36mstate\u001b[0m =\u001b[1;33m INFO\u001b[0m\n",
            "\u001b[1;36mreproducibility\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36mdata_path\u001b[0m =\u001b[1;33m dataset/downstream/Scientific\u001b[0m\n",
            "\u001b[1;36mcheckpoint_dir\u001b[0m =\u001b[1;33m saved\u001b[0m\n",
            "\u001b[1;36mshow_progress\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36msave_dataset\u001b[0m =\u001b[1;33m False\u001b[0m\n",
            "\u001b[1;36mdataset_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36msave_dataloaders\u001b[0m =\u001b[1;33m False\u001b[0m\n",
            "\u001b[1;36mdataloaders_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mlog_wandb\u001b[0m =\u001b[1;33m False\u001b[0m\n",
            "\n",
            "\u001b[1;35mTraining Hyper Parameters:\n",
            "\u001b[0m\u001b[1;36mepochs\u001b[0m =\u001b[1;33m 300\u001b[0m\n",
            "\u001b[1;36mtrain_batch_size\u001b[0m =\u001b[1;33m 2048\u001b[0m\n",
            "\u001b[1;36mlearner\u001b[0m =\u001b[1;33m adam\u001b[0m\n",
            "\u001b[1;36mlearning_rate\u001b[0m =\u001b[1;33m 0.003\u001b[0m\n",
            "\u001b[1;36mneg_sampling\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36meval_step\u001b[0m =\u001b[1;33m 1\u001b[0m\n",
            "\u001b[1;36mstopping_step\u001b[0m =\u001b[1;33m 10\u001b[0m\n",
            "\u001b[1;36mclip_grad_norm\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mweight_decay\u001b[0m =\u001b[1;33m 0.0\u001b[0m\n",
            "\u001b[1;36mloss_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
            "\n",
            "\u001b[1;35mEvaluation Hyper Parameters:\n",
            "\u001b[0m\u001b[1;36meval_args\u001b[0m =\u001b[1;33m {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'mode': 'full', 'group_by': 'user'}\u001b[0m\n",
            "\u001b[1;36mrepeatable\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36mmetrics\u001b[0m =\u001b[1;33m ['HIT', 'NDCG']\u001b[0m\n",
            "\u001b[1;36mtopk\u001b[0m =\u001b[1;33m [10, 50]\u001b[0m\n",
            "\u001b[1;36mvalid_metric\u001b[0m =\u001b[1;33m NDCG@10\u001b[0m\n",
            "\u001b[1;36mvalid_metric_bigger\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36meval_batch_size\u001b[0m =\u001b[1;33m 1024\u001b[0m\n",
            "\u001b[1;36mmetric_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
            "\n",
            "\u001b[1;35mDataset Hyper Parameters:\n",
            "\u001b[0m\u001b[1;36mfield_separator\u001b[0m =\u001b[1;33m \t\u001b[0m\n",
            "\u001b[1;36mseq_separator\u001b[0m =\u001b[1;33m  \u001b[0m\n",
            "\u001b[1;36mUSER_ID_FIELD\u001b[0m =\u001b[1;33m user_id\u001b[0m\n",
            "\u001b[1;36mITEM_ID_FIELD\u001b[0m =\u001b[1;33m item_id\u001b[0m\n",
            "\u001b[1;36mRATING_FIELD\u001b[0m =\u001b[1;33m rating\u001b[0m\n",
            "\u001b[1;36mTIME_FIELD\u001b[0m =\u001b[1;33m timestamp\u001b[0m\n",
            "\u001b[1;36mseq_len\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mLABEL_FIELD\u001b[0m =\u001b[1;33m label\u001b[0m\n",
            "\u001b[1;36mthreshold\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mNEG_PREFIX\u001b[0m =\u001b[1;33m neg_\u001b[0m\n",
            "\u001b[1;36mload_col\u001b[0m =\u001b[1;33m {'inter': ['user_id', 'item_id_list', 'item_id']}\u001b[0m\n",
            "\u001b[1;36munload_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36munused_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36madditional_feat_suffix\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mrm_dup_inter\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mval_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mfilter_inter_by_user_or_item\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36muser_inter_num_interval\u001b[0m =\u001b[1;33m [0,inf)\u001b[0m\n",
            "\u001b[1;36mitem_inter_num_interval\u001b[0m =\u001b[1;33m [0,inf)\u001b[0m\n",
            "\u001b[1;36malias_of_user_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36malias_of_item_id\u001b[0m =\u001b[1;33m ['item_id_list']\u001b[0m\n",
            "\u001b[1;36malias_of_entity_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36malias_of_relation_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mpreload_weight\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mnormalize_field\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mnormalize_all\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mITEM_LIST_LENGTH_FIELD\u001b[0m =\u001b[1;33m item_length\u001b[0m\n",
            "\u001b[1;36mLIST_SUFFIX\u001b[0m =\u001b[1;33m _list\u001b[0m\n",
            "\u001b[1;36mMAX_ITEM_LIST_LENGTH\u001b[0m =\u001b[1;33m 50\u001b[0m\n",
            "\u001b[1;36mPOSITION_FIELD\u001b[0m =\u001b[1;33m position_id\u001b[0m\n",
            "\u001b[1;36mHEAD_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m head_id\u001b[0m\n",
            "\u001b[1;36mTAIL_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m tail_id\u001b[0m\n",
            "\u001b[1;36mRELATION_ID_FIELD\u001b[0m =\u001b[1;33m relation_id\u001b[0m\n",
            "\u001b[1;36mENTITY_ID_FIELD\u001b[0m =\u001b[1;33m entity_id\u001b[0m\n",
            "\u001b[1;36mbenchmark_filename\u001b[0m =\u001b[1;33m ['train', 'valid', 'test']\u001b[0m\n",
            "\n",
            "\u001b[1;35mOther Hyper Parameters: \n",
            "\u001b[0m\u001b[1;36mwandb_project\u001b[0m = \u001b[1;33mrecbole\u001b[0m\n",
            "\u001b[1;36mrequire_pow\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
            "\u001b[1;36mMODEL_TYPE\u001b[0m = \u001b[1;33mModelType.SEQUENTIAL\u001b[0m\n",
            "\u001b[1;36mhidden_act\u001b[0m = \u001b[1;33mgelu\u001b[0m\n",
            "\u001b[1;36mlayer_norm_eps\u001b[0m = \u001b[1;33m1e-12\u001b[0m\n",
            "\u001b[1;36minitializer_range\u001b[0m = \u001b[1;33m0.02\u001b[0m\n",
            "\u001b[1;36mnum_tokens\u001b[0m = \u001b[1;33m7680\u001b[0m\n",
            "\u001b[1;36mdim\u001b[0m = \u001b[1;33m1024\u001b[0m\n",
            "\u001b[1;36mheads\u001b[0m = \u001b[1;33m8\u001b[0m\n",
            "\u001b[1;36mdepth\u001b[0m = \u001b[1;33m12\u001b[0m\n",
            "\u001b[1;36mmax_seq_len\u001b[0m = \u001b[1;33m300\u001b[0m\n",
            "\u001b[1;36mbucket_size\u001b[0m = \u001b[1;33m300\u001b[0m\n",
            "\u001b[1;36mcausal\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
            "\u001b[1;36mloss_type\u001b[0m = \u001b[1;33mCE\u001b[0m\n",
            "\u001b[1;36mtemperature\u001b[0m = \u001b[1;33m0.07\u001b[0m\n",
            "\u001b[1;36mcode_dim\u001b[0m = \u001b[1;33m32\u001b[0m\n",
            "\u001b[1;36mcode_cap\u001b[0m = \u001b[1;33m256\u001b[0m\n",
            "\u001b[1;36mhidden_size\u001b[0m = \u001b[1;33m300\u001b[0m\n",
            "\u001b[1;36mtrain_stage\u001b[0m = \u001b[1;33minductive_ft\u001b[0m\n",
            "\u001b[1;36mindex_path\u001b[0m = \u001b[1;33mdataset/downstream\u001b[0m\n",
            "\u001b[1;36mindex_pretrain_dataset\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
            "\u001b[1;36mindex_suffix\u001b[0m = \u001b[1;33mOPQ32,IVF1,PQ32x8.strict.index\u001b[0m\n",
            "\u001b[1;36mplm_suffix\u001b[0m = \u001b[1;33mfeat1CLS\u001b[0m\n",
            "\u001b[1;36mplm_size\u001b[0m = \u001b[1;33m768\u001b[0m\n",
            "\u001b[1;36msinkhorn_iter\u001b[0m = \u001b[1;33m3\u001b[0m\n",
            "\u001b[1;36mreassign_steps\u001b[0m = \u001b[1;33m5\u001b[0m\n",
            "\u001b[1;36mfake_idx_ratio\u001b[0m = \u001b[1;33m0.75\u001b[0m\n",
            "\u001b[1;36mtransform\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
            "\u001b[1;36mMODEL_INPUT_TYPE\u001b[0m = \u001b[1;33mInputType.POINTWISE\u001b[0m\n",
            "\u001b[1;36meval_type\u001b[0m = \u001b[1;33mEvaluatorType.RANKING\u001b[0m\n",
            "\u001b[1;36mdevice\u001b[0m = \u001b[1;33mcuda\u001b[0m\n",
            "\u001b[1;36mtrain_neg_sample_args\u001b[0m = \u001b[1;33m{'strategy': 'none'}\u001b[0m\n",
            "\u001b[1;36meval_neg_sample_args\u001b[0m = \u001b[1;33m{'strategy': 'full', 'distribution': 'uniform'}\u001b[0m\n",
            "\n",
            "\u001b[0m\n",
            "\u001b[0m18 Apr 20:16    INFO  Index path: dataset/downstream/Scientific/Scientific.OPQ32,IVF1,PQ32x8.strict.index\u001b[0m\n",
            "\u001b[0m18 Apr 20:16    INFO  \u001b[1;35mScientific\u001b[0m\n",
            "\u001b[1;34mThe number of users\u001b[0m: 8443\n",
            "\u001b[1;34mAverage actions of users\u001b[0m: 6.039445628997868\n",
            "\u001b[1;34mThe number of items\u001b[0m: 4386\n",
            "\u001b[1;34mAverage actions of items\u001b[0m: 11.637753937457202\n",
            "\u001b[1;34mThe number of inters\u001b[0m: 50985\n",
            "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 99.8623180504074%\n",
            "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id_list', 'item_id', 'item_length']\u001b[0m\n",
            "\u001b[0m18 Apr 20:16    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m negative sampling\u001b[0m: \u001b[1;33m[None]\u001b[0m\n",
            "\u001b[0m18 Apr 20:16    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'mode': 'full', 'group_by': 'user'}]\u001b[0m\n",
            "\u001b[0m18 Apr 20:16    INFO  Loading from pretrained/VQRec-FHCKM-300.pth\u001b[0m\n",
            "\u001b[0m18 Apr 20:16    INFO  Transfer [FHCKM] -> [\u001b[1;35mScientific\u001b[0m\n",
            "\u001b[1;34mThe number of users\u001b[0m: 8443\n",
            "\u001b[1;34mAverage actions of users\u001b[0m: 6.039445628997868\n",
            "\u001b[1;34mThe number of items\u001b[0m: 4386\n",
            "\u001b[1;34mAverage actions of items\u001b[0m: 11.637753937457202\n",
            "\u001b[1;34mThe number of inters\u001b[0m: 50985\n",
            "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 99.8623180504074%\n",
            "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id_list', 'item_id', 'item_length']]\u001b[0m\n",
            "\u001b[0m18 Apr 20:16    INFO  VQRec(\n",
            "  (pooler): Linear(in_features=300, out_features=300, bias=True)\n",
            "  (pq_code_embedding): Embedding(8224, 300, padding_idx=0)\n",
            "  (position_embedding): Embedding(300, 300)\n",
            "  (trm_encoder): AutoregressiveWrapper(\n",
            "    (net): Autopadder(\n",
            "      (net): SinkhornTransformerLM(\n",
            "        (to_token_emb): Embedding(7680, 1024)\n",
            "        (axial_pos_emb): AxialPositionalEmbedding()\n",
            "        (emb_dropout): Dropout(p=0.0, inplace=False)\n",
            "        (sinkhorn_transformer): SinkhornTransformer(\n",
            "          (layers): SequentialSequence(\n",
            "            (layers): ModuleList(\n",
            "              (0-11): 12 x ModuleList(\n",
            "                (0): PreNorm(\n",
            "                  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                  (fn): SinkhornSelfAttention(\n",
            "                    (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "                    (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
            "                    (to_out): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                    (local_attention): LocalAttention(\n",
            "                      (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    )\n",
            "                    (sinkhorn_attention): SinkhornCausalAttention(\n",
            "                      (sort_net): CausalAttentionSortNet()\n",
            "                      (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    )\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (1): PreNorm(\n",
            "                  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                  (fn): Chunk(\n",
            "                    (fn): FeedForward(\n",
            "                      (w1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                      (act): GELU(approximate='none')\n",
            "                      (dropout): Dropout(p=0.0, inplace=False)\n",
            "                      (w2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                    )\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (to_logits): Linear(in_features=1024, out_features=7680, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (loss_fct): CrossEntropyLoss()\n",
            ")\u001b[1;34m\n",
            "Trainable parameters\u001b[0m: 171950060\u001b[0m\n",
            "\u001b[0m18 Apr 20:16    INFO  Only index assignment tuned.\u001b[0m\n",
            "\u001b[1;35mTrain     0\u001b[0m:   0%|                                                           | 0/17 [00:00<?, ?it/s]\u001b[0m\u001b[0m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m  File \"/content/VQ-Rec/finetune.py\", line 82, in <module>\n",
            "\u001b[0m    \u001b[0mfinetune(args.m, args.d, pretrained_file=args.p, finetune_mode=args.f)\u001b[0m\n",
            "\u001b[0m  File \"/content/VQ-Rec/finetune.py\", line 55, in finetune\n",
            "\u001b[0m    \u001b[0mbest_valid_score, best_valid_result = trainer.fit(\u001b[0m\n",
            "\u001b[0m  File \"/content/VQ-Rec/trainer.py\", line 69, in fit\n",
            "\u001b[0m    \u001b[0mtrain_loss = self._train_epoch(train_data, epoch_idx, show_progress=show_progress)\u001b[0m\n",
            "\u001b[0m  File \"/content/VQ-Rec/trainer.py\", line 156, in _train_epoch\n",
            "\u001b[0m    \u001b[0mlosses = loss_func(interaction)\u001b[0m\n",
            "\u001b[0m  File \"/content/VQ-Rec/vqrecSink.py\", line 217, in calculate_loss\n",
            "\u001b[0m    \u001b[0mseq_output = self.forward(item_seq, item_seq_len)\u001b[0m\n",
            "\u001b[0m  File \"/content/VQ-Rec/vqrecSink.py\", line 145, in forward\n",
            "\u001b[0m    \u001b[0mtrm_output = self.trm_encoder(input_emb, output_all_encoded_layers=True)\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "\u001b[0m    \u001b[0mreturn forward_call(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/sinkhorn_transformer/autoregressive_wrapper.py\", line 98, in forward\n",
            "\u001b[0m    \u001b[0mreturn self.net(x, **kwargs)\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "\u001b[0m    \u001b[0mreturn forward_call(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/sinkhorn_transformer/autopadder.py\", line 68, in forward\n",
            "\u001b[0m    \u001b[0mout = self.net(x, **kwargs)\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "\u001b[0m    \u001b[0mreturn forward_call(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/sinkhorn_transformer/sinkhorn_transformer.py\", line 731, in forward\n",
            "\u001b[0m    \u001b[0mx = self.sinkhorn_transformer(x, **kwargs)\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "\u001b[0m    \u001b[0mreturn forward_call(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/sinkhorn_transformer/sinkhorn_transformer.py\", line 704, in forward\n",
            "\u001b[0m    \u001b[0mreturn self.layers(x, **kwargs)\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "\u001b[0m    \u001b[0mreturn forward_call(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/sinkhorn_transformer/reversible.py\", line 149, in forward\n",
            "\u001b[0m    \u001b[0mx = x + f(x, **f_args)\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "\u001b[0m    \u001b[0mreturn forward_call(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/sinkhorn_transformer/sinkhorn_transformer.py\", line 210, in forward\n",
            "\u001b[0m    \u001b[0mreturn self.fn(x, **kwargs)\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "\u001b[0m    \u001b[0mreturn forward_call(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/sinkhorn_transformer/sinkhorn_transformer.py\", line 633, in forward\n",
            "\u001b[0m    \u001b[0mout.append(self.sinkhorn_attention(q, k, v, q_mask = input_mask, kv_mask = kv_mask))\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "\u001b[0m    \u001b[0mreturn forward_call(*args, **kwargs)\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/sinkhorn_transformer/sinkhorn_transformer.py\", line 487, in forward\n",
            "\u001b[0m    \u001b[0mq, k, v = map(rotate_fn, (q, k, v))\u001b[0m\n",
            "\u001b[0m  File \"/usr/local/lib/python3.9/dist-packages/sinkhorn_transformer/sinkhorn_transformer.py\", line 453, in apply_fn_after_split_ind\n",
            "\u001b[0m    \u001b[0mreturn torch.cat((l, fn(r)), dim=dim)\u001b[0m\n",
            "\u001b[0mtorch.cuda\u001b[0m.\u001b[0mOutOfMemoryError\u001b[0m: \u001b[0mCUDA out of memory. Tried to allocate 2.34 GiB (GPU 0; 14.75 GiB total capacity; 13.65 GiB already allocated; 18.81 MiB free; 13.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ],
      "source": [
        "!python finetune.py -d Scientific -p pretrained/VQRec-FHCKM-300.pth --learning_rate=0.003"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}